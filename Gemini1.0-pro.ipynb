{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "H3VUbbydiENY",
      "metadata": {
        "id": "H3VUbbydiENY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1713472576552,
          "user_tz": 240,
          "elapsed": 122,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, ChatSession\n",
        "vertexai.init(project=\"alert-passkey-420723\", location=\"us-central1\")\n",
        "model=GenerativeModel(model_name=\"gemini-1.0-pro\",system_instruction=\" You are an intelligent programmer. You must complete the python function given to you by the user. And you must follow the format they present when giving your answer!\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DzXcclR9jX33",
      "metadata": {
        "id": "DzXcclR9jX33"
      },
      "outputs": [],
      "source": [
        "!conda create -n codex python=3.7\n",
        "! conda activate codex\n",
        "! git clone https://github.com/openai/human-eval\n",
        "! pip install -e human-eval\n",
        "# Set the working directory\n",
        "%cd /content/human-eval\n",
        "!pip install jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6ToKS92yOSwq",
      "metadata": {
        "id": "6ToKS92yOSwq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1713472579214,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "    \"temperature\": 0.0,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Iin5A4hchKFr",
      "metadata": {
        "id": "Iin5A4hchKFr",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1713472582138,
          "user_tz": 240,
          "elapsed": 106,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from human_eval.data import write_jsonl, read_problems\n",
        "import pandas as pd\n",
        "import time\n",
        "import jsonlines\n",
        "def generate_one_completion(prompt):\n",
        "  prompt_msg =  \"You are an intelligent programmer. You must complete the python function given to you by the user. And you must follow the format they present when giving your answer!\"+prompt\n",
        "  response = model.generate_content(prompt_msg,generation_config=generation_config)\n",
        "  return response.candidates[0].text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "EnuSFOQC7VQW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2893588,
          "status": "ok",
          "timestamp": 1713475659954,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "EnuSFOQC7VQW",
        "outputId": "736da9e9-7738-4cbf-b510-0316ab126a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.950490713119507\n",
            "2.950490713119507\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    jsonObj = pd.read_json(path_or_buf=\"https://github.com/openai/human-eval/raw/master/data/HumanEval.jsonl.gz\", lines=True)\n",
        "    command = 0\n",
        "    i = 0\n",
        "    durationTimes = []\n",
        "    with jsonlines.open('Gemini1.0-pro.jsonl', mode='w') as writer:\n",
        "      with jsonlines.open('GeminiTimer.jsonl', mode='w') as timer:\n",
        "        while i < 164:\n",
        "            if command < 4:\n",
        "                start_time = time.time()\n",
        "                response = generate_one_completion(jsonObj[\"prompt\"][i])\n",
        "                duration = time.time() - start_time\n",
        "                timer.write({jsonObj[\"task_id\"][i]: duration})\n",
        "                durationTimes.append(duration)\n",
        "                response = response.replace(\"```python\\n\", \"\")\n",
        "                response = response.replace(\"\\n```\", \"\")\n",
        "                completion = {'task_id': jsonObj[\"task_id\"][i], 'completion': response}\n",
        "                writer.write(completion)\n",
        "                i = i + 1\n",
        "                command = command + 1\n",
        "            else:\n",
        "                command = 0\n",
        "                time.sleep(60)\n",
        "    print(np.sum(duration))\n",
        "    print(np.average(duration))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 human_eval/evaluate_functional_correctness.py /content/Gemini1.0-pro.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdW3c46HMA6J",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1713477014191,
          "user_tz": 240,
          "elapsed": 2688,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "fa7009cb-af15-489f-88f6-5b249b251c8d"
      },
      "id": "KdW3c46HMA6J",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading samples...\n",
            "\r0it [00:00, ?it/s]\r164it [00:00, 15556.94it/s]\n",
            "Running test suites...\n",
            "100% 164/164 [00:02<00:00, 73.85it/s]\n",
            "Writing results to /content/Gemini1.0-pro.jsonl_results.jsonl...\n",
            "100% 164/164 [00:00<00:00, 36013.92it/s]\n",
            "{'pass@1': 0.3475609756097561}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/human-eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qa8ZcYnHQkE",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1713475756857,
          "user_tz": 240,
          "elapsed": 78,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d7c48850-2210-4f28-8465-30c307bb988a"
      },
      "id": "3Qa8ZcYnHQkE",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/human-eval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "vnDF4OaK7dI5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5317,
          "status": "ok",
          "timestamp": 1713476979237,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "vnDF4OaK7dI5",
        "outputId": "2e8de354-aabc-431f-c870-9542f0c74a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading samples...\n",
            "\r0it [00:00, ?it/s]\r164it [00:00, 21170.97it/s]\n",
            "Running test suites...\n",
            "100% 164/164 [00:04<00:00, 34.02it/s]\n",
            "Writing results to output.jsonl_results.jsonl...\n",
            "100% 164/164 [00:00<00:00, 35095.20it/s]\n",
            "{'pass@1': 0.676829268292683}\n"
          ]
        }
      ],
      "source": [
        "!python3 human_eval/evaluate_functional_correctness.py output.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def replace_newlines(input_file, output_file):\n",
        "\n",
        "  with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "    for line in infile:\n",
        "      entry = json.loads(line)\n",
        "      completion = entry[\"completion\"].replace(\"```\\n\", \"\")\n",
        "      entry[\"completion\"] = completion\n",
        "      # Write modified entry back to output file with newline\n",
        "      outfile.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_file = '/content/Gemini1.0-pro.jsonl'\n",
        "output_file = 'output.jsonl'\n",
        "replace_newlines(input_file, output_file)\n",
        "\n",
        "print(f'Successfully processed {input_file} and wrote results to {output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiatKwLtH4v2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1713476951326,
          "user_tz": 240,
          "elapsed": 103,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9e3d83a7-44fa-4992-8d94-a1d6523499a3"
      },
      "id": "GiatKwLtH4v2",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully processed /content/Gemini1.0-pro.jsonl and wrote results to output.jsonl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Gemini1.0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}